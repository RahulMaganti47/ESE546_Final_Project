# -*- coding: utf-8 -*-
"""MAML+Mujoco

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pUx0onzAdHv2lHEl9BUQ8SF-MH992_Ol

## **Simulation Environment is from CS330_fall2020**

The following simulation environment is from a homework stencil from Stanford's CS330_fall2020: Goal Conditioned Reinforcement Learning and Hindsight Experience Replay.

https://colab.research.google.com/drive/1uYqzq4Ix91DD4QdElyrbC_If0TKDf_3t?usp=sharing#scrollTo=5yTRSgI-ryd-
"""

# Commented out IPython magic to ensure Python compatibility.
import os
from google.colab import drive
drive.mount('/content/gdrive')

#@title set up mount symlink

DRIVE_PATH = '/content/gdrive/My\ Drive/finalproj'
DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\', '')
if not os.path.exists(DRIVE_PYTHON_PATH):
#   %mkdir $DRIVE_PATH

## the space in `My Drive` causes some issues,
## make a symlink to avoid this
SYM_PATH = '/content/finalproj'
if not os.path.exists(SYM_PATH):
  !ln -s $DRIVE_PATH $SYM_PATH

#@title Install Requirements
#@markdown Requirements for the assignment and display drivers

# Robot sim
!pip install gym==0.15.4
!pip install pygame

# Various things for render
!apt-get install python-opengl -y
!apt install xvfb -y

# Rendering Environment
!pip install pyvirtualdisplay
!pip install piglet
!sudo apt-get install -y xvfb ffmpeg
!pip install imageio
!pip install PILLOW

# Commented out IPython magic to ensure Python compatibility.
#@title Download Mujoco from an online repository

MJC_PATH = '{}/mujoco'.format(SYM_PATH)
if not os.path.exists(MJC_PATH):
#   %mkdir $MJC_PATH
# %cd $MJC_PATH
if not os.path.exists(os.path.join(MJC_PATH, 'mujoco200')):
  !wget -q https://www.roboti.us/download/mujoco200_linux.zip
  !unzip -q mujoco200_linux.zip
#   %mv mujoco200_linux mujoco200
#   %rm mujoco200_linux.zip

#@title Important: ACTION Required BEFORE running this cell
#@markdown Place the mujoco key we have given you into a text file called mjkey.txt 
#@markdown and ensure that the mujoco key is in the Google Drive path `cs330_fall2020/mujoco`.

import os

os.environ['LD_LIBRARY_PATH'] += ':{}/mujoco200/bin'.format(MJC_PATH)
os.environ['MUJOCO_PY_MUJOCO_PATH'] = '{}/mujoco200'.format(MJC_PATH)
os.environ['MUJOCO_PY_MJKEY_PATH'] = '{}/mjkey.txt'.format(MJC_PATH)

## installation on colab does not find *.so files
## in LD_LIBRARY_PATH, copy over manually instead
!cp $MJC_PATH/mujoco200/bin/*.so /usr/lib/x86_64-linux-gnu/

#@title Important system updates for mujoco-py
!apt update 
!apt install -y --no-install-recommends \
        build-essential \
        curl \
        git \
        gnupg2 \
        make \
        cmake \
        ffmpeg \
        swig \
        libz-dev \
        unzip \
        zlib1g-dev \
        libglfw3 \
        libglfw3-dev \
        libxrandr2 \
        libxinerama-dev \
        libxi6 \
        libxcursor-dev \
        libgl1-mesa-dev \
        libgl1-mesa-glx \
        libglew-dev \
        libosmesa6-dev \
        lsb-release \
        ack-grep \
        patchelf \
        wget \
        xpra \
        xserver-xorg-dev \
        xvfb \
        python-opengl \
        ffmpeg > /dev/null 2>&1

# Commented out IPython magic to ensure Python compatibility.
#@title Clone and install mujoco-py
#@markdown Remember that you need to put the key in the appropriate location as described above
# %cd $MJC_PATH
if not os.path.exists('mujoco-py'):
  !git clone https://github.com/openai/mujoco-py.git
# %cd mujoco-py
# %pip install -e .

## cythonize at the first import
import mujoco_py

# Commented out IPython magic to ensure Python compatibility.
#@title Clone and install multiworld
# %cd $SYM_PATH
!git clone https://github.com/vitchyr/multiworld.git

# %cd multiworld
# %pip install -e .

#@title Sets up virtual display
from pyvirtualdisplay import Display
display = Display(visible=0, size=(1400, 900))
display.start()

# Commented out IPython magic to ensure Python compatibility.
#@title Check imports and add helper functions for display

import os
import gym
from gym import logger as gymlogger
from gym.wrappers import Monitor
gymlogger.set_level(40) # error only
import tensorflow as tf
import numpy as np
import random
import matplotlib
import matplotlib.pyplot as plt
import math
import glob
import io
import base64
from IPython.display import HTML

from IPython import display as ipythondisplay
if type(os.environ.get("DISPLAY")) is not str or len(os.environ.get("DISPLAY"))==0:
    !bash ../xvfb start
#     %env DISPLAY=:1

def show_video():
  mp4list = glob.glob('video/*.mp4')
  if len(mp4list) > 0:
    mp4 = mp4list[0]
    video = io.open(mp4, 'r+b').read()
    encoded = base64.b64encode(video)
    ipythondisplay.display(HTML(data='''<video alt="test" autoplay 
                loop controls style="height: 400px;">
                <source src="data:video/mp4;base64,{0}" type="video/mp4" />
             </video>'''.format(encoded.decode('ascii'))))
  else: 
    print("Could not find video")
    

def wrap_env(env):
  env = Monitor(env, './video', force=True)
  return env

"""## **Test Rendering**"""

#@title After running, you should see a video play
matplotlib.use('Agg')

env = wrap_env(gym.make("Ant-v2"))

observation = env.reset()
for i in range(10):
    env.render(mode='rgb_array')
    obs, rew, term, _ = env.step(env.action_space.sample() ) 
    if term:
      break;
            
env.close()
print('Loading video...')
show_video()

# Commented out IPython magic to ensure Python compatibility.
# %cd ../

"""## **PyTorch MAML Implementation from Public Github Repo**
Link to repo: https://github.com/tristandeleu/pytorch-maml-rl
"""

!git clone https://github.com/tristandeleu/pytorch-maml-rl.git

# Commented out IPython magic to ensure Python compatibility.
# %cd pytorch-maml-rl
!pip install -r requirements.txt

!python train.py --config configs/maml/halfcheetah-vel.yaml --output-folder maml-halfcheetah-vel --seed 1 --num-workers 8 --use-cuda

!python test.py --config maml-halfcheetah-vel/config.json --policy maml-halfcheetah-vel/policy.th --output maml-halfcheetah-vel/results.npz --meta-batch-size 20 --num-batches 10  --num-workers 8

# Commented out IPython magic to ensure Python compatibility.
!pwd
# %cd maml-halfcheetah-vel

"""Display Results """

x = np.load('results.npz')

print(x)  
x.files
np.mean(x['valid_returns'])

"""## **CAML Implementation**

Algorithm to solve issues with lifelong learning. Ordered sequence of task: 
1. HalfCheetah (varying velocities - going up to train)  
2. HalfCheetah (varying velocities - going down) 

Priorization Schemes
1. oldest 
"""

#learn sequentially up